# Kavak Hackathon ‚Äî Bandits + LLM Agents (Agents API)

**Meta**: Demo en <6‚ÄØh que auto-aprende (bandits + evaluador LLM) y muestra lift en NPS simulado, churn/engagement y qu√© estrategia (plantilla) conviene por cohorte. Todo in-memory sobre Streamlit y OpenAI Agents API.

---

## 0) Plan por fases (6‚ÄØh disponibles)

| Fase | Duraci√≥n | Objetivo | Entregables clave |
| --- | --- | --- | --- |
| **F0: Kickoff & setup** | 0:00‚Äì0:30 | Alinear demo, preparar entorno, definir owners | `requirements` instalados, API key seteada, backlog priorizado |
| **F1: Datos & estructura** | 0:30‚Äì2:00 | Simulador + modelos + session state + UI esqueleto | `PersonaForge`, `StateBuilder`, `SessionState`, layout Streamlit con tabs/botones |
| **F2: Agents & bandits** | 2:00‚Äì3:30 | Integrar OpenAI Agents (Responder/Outreach/Judge) + policy learner | `AgentsRunner`, prompts finales, loop vocal/outreach con reward |
| **F3: M√©tricas & dashboard** | 3:30‚Äì4:30 | M√©tricas agregadas, charts, insights, safety guardrails | Dashboard con KPIs, tablas por cohorte, safety en producci√≥n |
| **F4: Hardening & demo script** | 4:30‚Äì5:15 | QA r√°pida, fallback flows, baseline compare, guion de demo | Dataset baseline, pantalla ‚Äúcaso individual‚Äù, script narrativo |
| **F5: Infra & Polish** | 5:15‚Äì6:00 | Dockerizar, artefactos demo-ready, slides | Dockerfile, script batch, 5 slides cristalinas, dry-run completo |

**Paralelizaci√≥n sugerida**  
1. **Persona & datos**: mantiene `PersonaForge`, `Prioritizer`, datasets.  
2. **Agents & prompts**: define `Responder/Outreach/Judge`, safety.  
3. **Bandits & m√©tricas**: policy learner + KPIs/plots.  
4. **Streamlit owner**: integra piezas y cuida UX.

---

## 0) MVP express (üéØ listo en 60‚ÄØmin)

### Objetivo
1. Simular 4 perfiles: vocal-feliz, vocal-enojado, no-vocal-feliz, no-vocal-enojado (50 c/u ‚Üí 200 clientes).
2. Para vocales: agente Responder + bandit (Thompson o Œµ-greedy) elige 1 de 5 plantillas y aprende con evaluador LLM `{NPS_expected, EngagementProb, ChurnProb}`.
3. Para no-vocales: agente Outreach prioriza top-30 v√≠a heur√≠stica + bandit y aprende igual.
4. Streamlit muestra m√©tricas: lift NPS, churn/engagement, top plantillas x segmento/issue, logs de mensajes y racionales.

### Supuestos
- Dataset sint√©tico generado por PersonaForge (mini historia, se√±ales transaccionales, mensaje inicial si es vocal).
- Recompensa: `R = clip0_1(0.6*NPS + 0.3*(EngProb*10) - 0.3*(ChurnProb*10))`.
- Evaluador (`Judge`) retorna JSON estricto sin humanos en el loop.
- Pol√≠tica contextual: `context = (segmento, issue_bucket)` ‚Üí actualiza priors online.
- Sin persistencia, todo en session state.

### Arquitectura m√≠nima
```
PersonaForge ‚Üí StateBuilder ‚Üí TemplateFactory
                 ‚Üì                        ‚Üì
            Policy Learner -------‚Üí Responder / Outreach (Agents API)
                                          ‚Üì
                                   Judge (Agents API JSON)
                                          ‚Üì
                             compute_reward ‚Üí policy.update
```

Tabs Streamlit: Simulaci√≥n | Conversaciones | Outreach | M√©tricas | Recomendaciones.

### Flujo para demo (5 mins)
1. Click ‚ÄúGenerar dataset sint√©tico‚Äù.
2. Click ‚ÄúEjecutar iteraci√≥n‚Äù ‚Üí procesa vocales + outreach top-30.
3. Revisar Dashboard (KPIs, gr√°ficos, insights) y Conversaciones/Outreach (mensajes + scores).
4. Repetir 1‚Äì3 veces para mostrar aprendizaje real-time.

---

## 1) Caso de negocio (pitch r√°pido)

**Problema**  
- Vocals concentran se√±ales; non-vocals = zona ciega.  
- Outreach wrong-time desperdicia el ‚Äúone-shot‚Äù.  
- Imposible A/B manual a escala.

**Soluci√≥n (MVP)**  
Agentes que simulan clientes + agentes operativos (Responder/Outreach) que aprenden online con bandits, guiados por un evaluador LLM (Judge) que estima NPS/churn/engagement y aspect sentiment.

**KPIs demo**  
- Œî NPS esperado vs baseline (plantilla uniforme).  
- Churn esperado ‚Üì.  
- Engagement esperado ‚Üë.  
- Precisi√≥n de selecci√≥n (expected engagement) en no-vocales top-N.

**Impacto esperado (fase real)**  
- +2‚Äì5 pts NPS en 4‚Äì8 semanas.  
- ‚àí10‚Äì20‚ÄØ% churn conversacional.  
- Menos retrabajo v√≠a rutas correctas (mec√°nico/finanzas).

**Costos & tiempo**  
- Hoy: prototipo in-memory sin integraci√≥n.  
- Pronto: conectar CRM/tickets (2‚Äì4 semanas).  
- Coste variable = tokens (hackathon: ilimitado). Caching/batching luego.

**Riesgos & mitigaci√≥n**  
- Sesgo auto-selecci√≥n ‚Üí logging + estratificaci√≥n + holdouts.  
- Sobre-ajuste plantillas ‚Üí Thompson/Œµ mantiene exploraci√≥n.  
- Tono inadecuado ‚Üí guardrails (Safety Checker) + blacklist.

---

## 2) Hoja de ruta (post-MVP)

**Semana 1‚Äì2**  
- Plug CRM hist√≥rico (NPS, tickets, pagos).  
- Features adicionales (canal, respuesta previa, taxonom√≠a de issues).  
- Plantillas con micro-acciones (cup√≥n %, derivaci√≥n expl√≠cita, SLA).

**Semana 3‚Äì4**  
- Aspect-Based Sentiment (ABS) propio por {finanzas, mec√°nica, log√≠stica, atenci√≥n}.  
- Off-policy eval (IPS/DR) para testear nuevas pol√≠ticas sin full deployment.  
- Personalizaci√≥n via embeddings (RAG liviano por cliente).

**Semana 5‚Äì8**  
- Contextual bandits (LinUCB/NeuralUCB).  
- Multi-objetivo con restricciones (cost-to-serve).  
- Causal uplift para outreach en no-vocales.  
- Medir ŒîLTV/cohort + costo de beneficios.

---

## 3) Streamlit (estructura + hooks)

**Tabs & contenido**
- **Simulaci√≥n**: sliders (n clientes, %enojados, %vocales), bot√≥n dataset.  
- **Conversaciones**: tabla expandible (mensaje, score Judge, plantilla, rationale).  
- **Outreach**: ranking top-30 no-vocales (score + mensaje).  
- **M√©tricas**:  
  - L√≠nea: reward/NPS por iteraci√≥n.  
  - Barras: churn/engagement por segmento.  
  - Dataframes: resumen por arm/segment/issue.  
- **Recomendaciones**: insights auto-generados (‚ÄúPara NVE-mec√°nica ‚Üí Emp√°tico + SLA 48h‚Äù).

**Session state**: `customers`, `logs`, `policy`, `iteration`, `baseline_logs?`.

**Key buttons**: Generar dataset | Ejecutar iteraci√≥n (procesa vocal+outreach).  
Opcional: botones separados (solo vocales / solo outreach) si se quiere granularidad.

---

## 4) Plantillas & Prompts (Agents API)

**Templates (m√°x 5)**
1. `empatiko` ‚Äî Emp√°tico breve  
2. `tecnico` ‚Äî T√©cnico soluci√≥n  
3. `cupon` ‚Äî Compensaci√≥n/cup√≥n  
4. `escalar` ‚Äî Escalaci√≥n interna  
5. `seguimiento` ‚Äî Seguimiento proactivo  

Slots: `[saludo, reconocimiento_issue/diagn√≥stico, accion/accion_tecnica, next_step/sla/next_touch, firma]`.  
Guardrails: no culpar, disculpa breve cuando aplique, SLA claro, sin promesas imposibles, l√≠mite de compensaci√≥n.

**System prompts**  
- **Responder**: ‚ÄúEres agente Kavak‚Ä¶ usa UNA plantilla, rellena slots con contexto, no culpes, ofrece next step claro, escalar cuando aplique, m√°x 150 palabras, responde solo texto final.‚Äù  
- **Outreach**: ‚ÄúAgente outreach one-shot‚Ä¶ personaliza con recencia/monto/issue, CTA claro, m√°x 120 palabras, solo texto.‚Äù  
- **Judge**: ‚ÄúEval√∫a mensaje dado contexto, devuelve JSON estricto `{NPS_expected 0-10, EngagementProb 0-1, ChurnProb 0-1, AspectSentiment (finanzas/mecanica/logistica/atencion -1..1), rationale <=280 chars}`; penaliza frialdad, valora claridad + SLA.‚Äù

---

## 5) Datos sint√©ticos (CSV m√≠nimo)

```
customer_id, segment{VF,VE,NVF,NVE}, is_vocal, last_purchase_days,
price, issues_flag{0/1}, past_NPS, first_message, channel_pref,
churn_risk_est, issue_bucket, mini_story
```

Opcionales √∫teis: `messages[]`, `sentiment_hist[]` (para versiones extendidas).  
PersonaForge genera: mini bio, historia, primer mensaje (si vocal), issue bucket, banderas de enojo.

Prioritizer heur√≠stico:  
`S = 0.5*issues_flag + 0.3*normalize(price) + 0.2*normalize(1/last_purchase_days)`  
‚Üí rank top-N no-vocales.

---

## 6) Loop de aprendizaje (pseudo)

```python
for customer in vocal_customers:
    ctx = state_builder.build(customer)
    arm = policy.select((ctx.segment, ctx.issue_bucket))
    draft = template_factory.fill(arm, ctx)
    msg = responder.run(ctx, draft)              # Agents API ‚Üí texto
    is_safe, _ = safety.check(msg)
    if not is_safe:
        msg = responder._fallback_message(ctx)
    score = judge.run(ctx, msg)                  # Agents API ‚Üí JSON (Score)
    reward = compute_reward(score)               # clip 0..1
    policy.update(arm, reward, (ctx.segment, ctx.issue_bucket))
    logs.append(InteractionLog(...))

non_vocals = prioritizer.rank(no_vocal_customers)[:30]
repetir mismo patr√≥n con OutreachAgent
```

---

## 7) 5 Slides ‚Äúcristalinos‚Äù
1. **Problema** ‚Äì Vocals = mucha se√±al; non-vocals = ciegos. Outreach y soporte pierden potencia.  
2. **Soluci√≥n** ‚Äì Simulaci√≥n + agentes operativos con bandits + evaluador LLM ‚Üí loop prueba-mide-aprende.  
3. **Demo & M√©tricas** ‚Äì NPS‚Üë, churn‚Üì, engagement‚Üë; gr√°fico evoluci√≥n + tabla mejores plantillas.  
4. **Valor Kavak** ‚Äì Priorizaci√≥n inteligente, tono perfecto desde el primer mensaje, rutas correctas ‚Üí menos retrabajo/costo.  
5. **Next Steps & ROI** ‚Äì De bandits simples a contextuales, ABS, uplift. Meta: +2‚Äì5 NPS, ‚àí10‚Äì20% churn en 4‚Äì8 semanas.

---

## 8) Checklist t√©cnico (Agents API, ~60‚ÄØmin)

> Tips: 3 personas en paralelo ‚Üí (1) Streamlit, (2) prompts/agents, (3) bandit + scoring.  
> Set `OPENAI_API_KEY` una sola vez (clave de hackathon).

### A. Entorno (5‚ÄØmin)
- `python -m venv venv && source venv/bin/activate`
- `pip install -r requirements.txt` (incluye `openai>=1.16`)
- `export OPENAI_API_KEY=...`

### B. Datos & modelos (10‚ÄØmin)
- Implementar `PersonaForge` (listo).  
- `StateBuilder`, `TemplateFactory`, `Score`, `InteractionLog` (listo).  
- `data_sim.generate_customers` ‚Üí DataFrame/CSV (listo).

### C. Bandit (10‚ÄØmin)
- `ThompsonBandit` por contexto `(segmento, issue)` (ya implementado).  
- Reward clipping in `scoring.compute_reward`.  
- Opcional `EpsilonGreedy` con `epsilon=0.1`.

### D. Agents (15‚ÄØmin)
- `AgentsRunner` (Responses API).  
- `ResponderAgent`, `OutreachAgent` ‚Üí `run_text`.  
- `Judge` ‚Üí `run_json` + `Score` validation.  
- Safety guardrails (`SafetyChecker`).

### E. Streamlit (15‚ÄØmin)
- Sidebar: config + acciones.  
- Buttons ‚Üí disparan loops (ya implementado en `streamlit_app.py`).  
- Tabs con gr√°ficos (plotly) y tablas.  
- `st.session_state` para persistir dataset / logs / policy / iteration.

### F. Testing r√°pido (5‚ÄØmin)
- Ejecutar `streamlit run app/streamlit_app.py`.  
- Generar dataset, correr iteraci√≥n, verificar logs y m√©tricas.  
- Confirmar JSON Judge v√°lido (ver consola si fallback).  
- Ajustar tokens/temperatura si hay cortes.

### G. Demo script
1. Mostrar un cliente enojado antes/despu√©s (mensaje + scores).  
2. Mostrar gr√°fico de evoluci√≥n (reward/NPS).  
3. Destacar insight: ‚ÄúPara NVE mec√°nica ‚Üí Escalar + Emp√°tico‚Äù.  
4. Mencionar roadmap y ROI.

---

## 9) ‚ÄúModo BASIC‚Äù (si hay poco tiempo)
- Plantillas: s√≥lo `empatiko` y `cupon`.  
- Segmentos: `VE` (vocal enojado) y `NVE` (no vocal enojado).  
- Iteraciones: 2 loops.  
- Sigue mostrando aprendizaje (bandit converge).

---

## 10) Ap√©ndice ‚Äî Repositorio esperado

```
app/
  streamlit_app.py
  data_sim.py
  templates.py
  scoring.py
  models.py
  factories/
    persona_forge.py
    state_builder.py
    template_factory.py
    responders.py
    judge.py
    policy_learner.py
    prioritizer.py
    metrics.py
    safety.py
    agents_runner.py
requirements.txt
README.md
AGENTS.md
Dockerfile
.dockerignore
scripts/run_experiment.py
context_engineering/
```

## 11) Infra r√°pida & ejecuci√≥n en nube

- **Docker**: `docker build -t kavak-agents .`  
  Ejecutar experimento:  
  `docker run --rm -e OPENAI_API_KEY=$OPENAI_API_KEY -v $(pwd)/profiles:/app/profiles kavak-agents python scripts/run_experiment.py profiles --output results/iter1.csv`
- **Resultados**: `scripts/run_experiment.py` genera DataFrame con `{client_id, NPS_final, LTV_final, ganancia_LTV, ...}` y summary; ideal para conectarlo a Streamlit/Gr√°ficas.
- **Loop completo**: Planner ‚Üí Conversaci√≥n 1:1 ‚Üí Judge ‚Üí LTV Evaluator ‚Üí Registro ‚Üí Prompt Tuner (reutiliza summaries para evolucionar prompt).

Esto deja todo listo para montar una UI (Streamlit) en la VM sin tocar la l√≥gica.

Listo para hackathon: ‚Äúauto-aprende‚Äù, tokens ilimitados, valor claro en minutos. !*** End Patch
